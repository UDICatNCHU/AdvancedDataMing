{"cells":[{"cell_type":"code","source":["weather_data = sc.textFile(\"/FileStore/tables/pm2_5Taiwan-3b69f.csv\")"],"metadata":{"collapsed":false},"outputs":[],"execution_count":1},{"cell_type":"code","source":["weather_data_rdd = weather_data.map(lambda line : line.split(\",\"))\nfor x in weather_data_rdd.take(30):\n    for i in range(len(x)):\n        print x[i],\n    print \"\""],"metadata":{"collapsed":false},"outputs":[],"execution_count":2},{"cell_type":"code","source":["pm25schema = weather_data_rdd.first()\nprint pm25schema"],"metadata":{"collapsed":false},"outputs":[],"execution_count":3},{"cell_type":"code","source":["import math\ndef remove_row_with_noise (x):\n    for i in range(3, len(x)):\n        if not x[i].isdecimal():\n            return False\n    return True "],"metadata":{"collapsed":false},"outputs":[],"execution_count":4},{"cell_type":"code","source":["clean_weather_data = weather_data_rdd\\\n                    .filter(lambda x: x!=pm25schema)\\\n                    .filter(remove_row_with_noise)\nclean_weather_data.cache()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":5},{"cell_type":"code","source":["dalipm25 = clean_weather_data.filter(lambda x: x[1] == u'大里')"],"metadata":{"collapsed":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.sql import SQLContext\nfrom pyspark.sql import Row\ndalipm25row = dalipm25.map(lambda p:\n        Row(\n        date = p[0],\n        location = p[1],\n        measure = p[2],\n        hr_01 = float(p[3]), hr_02 = float(p[4]),hr_03 = float(p[5]),hr_04 = float(p[6]),hr_05 = float(p[7]),\n        hr_06 = float(p[8]),hr_07 = float(p[9]),hr_08 = float(p[10]),hr_09 = float(p[11]),hr_10 = float(p[12]),\n        hr_11 = float(p[13]),hr_12 = float(p[14]),hr_13 = float(p[15]),hr_14 = float(p[16]),hr_15 = float(p[17]),\n        hr_16 = float(p[18]),hr_17 = float(p[19]),hr_18 = float(p[20]),hr_19 = float(p[21]),hr_20 = float(p[22]),\n        hr_21 = float(p[23]),hr_22 = float(p[24]),hr_23 = float(p[25]),hr_24 = float(p[26]),\n    )\n)\n\n\ndalipm25row.take(5)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":7},{"cell_type":"code","source":["df = sqlContext.createDataFrame(dalipm25row)"],"metadata":{"collapsed":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":["df.show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":9},{"cell_type":"code","source":["df_pm10 = df.select(df.date.alias(\"datepm10\"),df.hr_09.alias(\"hr_09_pm10\"),df.hr_10.alias(\"hr_10_pm10\"), df.hr_11.alias(\"hr_11_pm10\"),df.hr_12.alias(\"hr_12_pm10\"), \"measure\").filter(df.measure==\"PM10\")\ndf_pm25 = df.select(df.date.alias(\"datepm25\"),df.hr_09.alias(\"hr_09_pm25\"),df.hr_10.alias(\"hr_10_pm25\"), df.hr_11.alias(\"hr_11_pm25\"),df.hr_12.alias(\"hr_12_pm25\"), \"measure\").filter(df.measure==\"PM2.5\") \ndf_AMB_TEMP = df.select(df.date.alias(\"dateAMB_TEMP\"),df.hr_09.alias(\"hr_09_AMB_TEMP\"),df.hr_10.alias(\"hr_10_AMB_TEMP\"), df.hr_11.alias(\"hr_11_AMB_TEMP\"),df.hr_12.alias(\"hr_12_AMB_TEMP\"), \"measure\").filter(df.measure==\"AMB_TEMP\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":["traing_data = df_pm25\\\n    .join(df_pm10, df_pm25.datepm25==df_pm10.datepm10)\\\n    .join(df_AMB_TEMP, df_pm25.datepm25==df_AMB_TEMP.dateAMB_TEMP).drop(\"dateAMB_TEMP\").drop(\"measure\").drop(\"datepm10\")"],"metadata":{"collapsed":false},"outputs":[],"execution_count":11},{"cell_type":"code","source":["traing_data.show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":12},{"cell_type":"code","source":["traing_data.corr(\"hr_09_pm25\", \"hr_10_pm25\")"],"metadata":{"collapsed":false},"outputs":[],"execution_count":13},{"cell_type":"code","source":["traing_data.show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.sql import functions as F\nformulated_traning_data = traing_data.select(\"*\", F.when(traing_data.hr_12_pm25 > 50, 1).otherwise(0)).withColumnRenamed(\"CASE WHEN (hr_12_pm25 > 50) THEN 1 ELSE 0 END\", \"pm25_condiction\").\\\ndrop(\"hr_12_AMB_TEMP\").drop(\"hr_12_pm10\").drop(\"hr_12_pm25\").drop(\"datepm25\")"],"metadata":{"collapsed":false},"outputs":[],"execution_count":15},{"cell_type":"code","source":["formulated_traning_data.show()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":16},{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\n\nLabelPoints = formulated_traning_data.rdd\\\n            .map(lambda r: LabeledPoint(r.pm25_condiction, \\\n                                        [r.hr_09_pm25, r.hr_10_pm25, r.hr_11_pm25, \\\n                                         r.hr_09_pm10, r.hr_10_pm10, r.hr_11_pm10, \\\n                                         r.hr_09_AMB_TEMP, r.hr_10_AMB_TEMP, r.hr_11_AMB_TEMP]))\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":17},{"cell_type":"code","source":["(trainData,validationData,testData) = LabelPoints.randomSplit([6,0,4])"],"metadata":{"collapsed":false},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.mllib.tree import DecisionTree\nDTModel = DecisionTree.trainClassifier(trainData,\n        numClasses=2,\n        categoricalFeaturesInfo={},\n        impurity=\"entropy\",\n        maxDepth=3,\n        maxBins=5)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":19},{"cell_type":"code","source":["prediction = DTModel.predict(testData.map(lambda x: x.features))"],"metadata":{"collapsed":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":["predictionAndLabels = prediction.zip(testData.map(lambda x: x.label))"],"metadata":{"collapsed":false},"outputs":[],"execution_count":21},{"cell_type":"code","source":["predictionAndLabels.collect()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":22},{"cell_type":"code","source":["from pyspark.mllib.evaluation import BinaryClassificationMetrics\nmetrics = BinaryClassificationMetrics(predictionAndLabels)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":23},{"cell_type":"code","source":["print metrics.areaUnderROC"],"metadata":{"collapsed":false},"outputs":[],"execution_count":24},{"cell_type":"code","source":[""],"metadata":{"collapsed":true},"outputs":[],"execution_count":25}],"metadata":{"kernelspec":{"display_name":"Python 2 with Spark 2.0","language":"python","name":"python2-spark20"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"PM25+Prediction","notebookId":1414086157091548},"nbformat":4,"nbformat_minor":0}
